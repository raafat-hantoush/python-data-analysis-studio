{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import/Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=reset\n",
    "#step_name=reset\n",
    "#step_type=import/export\n",
    "#step_desc=reload the original data frame from the csv file.\n",
    "df=pd.read_csv(\"/Users/raafat.hantoush/Documents/GitHub/general/work_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=import_required_libs\n",
    "#step_name=import required libraries\n",
    "#step_type=import/export\n",
    "#step_desc=import the required python libraries\n",
    "import pandas as pd\n",
    "import numpy as np;\n",
    "import scipy;\n",
    "## plotting libraries\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "## stats Libraries\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "## Sklearn libraries\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics as metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model as lm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=load_regression_sample_datasets\n",
    "#step_name=load regression sample datasets\n",
    "#step_type=import/export\n",
    "#step_desc=load regression sample datasets\n",
    "import sklearn.datasets\n",
    "## comment the unneeded data sets\n",
    "\n",
    "## regression dat sets \n",
    "X, y=sklearn.datasets.load_diabetes(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=load_classification_sample_datasets\n",
    "#step_name=load classification sample datasets\n",
    "#step_type=import/export\n",
    "#step_desc=load classification sample datasets\n",
    "import sklearn.datasets\n",
    "## comment the unneeded data sets\n",
    "## classification data sets\n",
    "X, y= sklearn.datasets.load_breast_cancer(return_X_y=True,as_frame=True)\n",
    "X, y= sklearn.datasets.load_iris(return_X_y=True,as_frame=True)\n",
    "X, y= sklearn.datasets.load_wine(return_X_y=True,as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=load_cclustering_sample_datasets\n",
    "#step_name=load clustering sample datasets\n",
    "#step_type=import/export\n",
    "#step_desc=load clustering sample datasets\n",
    "import sklearn.datasets\n",
    "## comment the unneeded data sets\n",
    "\n",
    "## clustering data sets\n",
    "df= datasets.load_wine(as_frame=True)[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=load_pickle_file\n",
    "#step_name=load pickle file\n",
    "#step_type=import/export\n",
    "#step_desc=load pickle file\n",
    "import pickle\n",
    "def load(filename = \"filename.pickle\"): \n",
    "    try: \n",
    "        with open(filename, \"rb\") as f: \n",
    "            return pickle.load(f) \n",
    "        \n",
    "    except FileNotFoundError: \n",
    "        print(\"File not found!\") \n",
    "        \n",
    "## calling the function\n",
    "loaded_pickle = load(\"Model/scaler.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=dump_pickle_file\n",
    "#step_name=dump pickle file\n",
    "#step_type=import/export\n",
    "#step_desc=dump pickle file\n",
    "import pickle\n",
    "\n",
    "with open(filepath, \"wb\") as f:\n",
    "    pickle.dump(object_to_be_saved,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=export_data_to_csv\n",
    "#step_name=export data to csv\n",
    "#step_type=import/export\n",
    "#step_desc=export pandas data frame to csv file\n",
    "df.to_csv ('', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=custom_code\n",
    "#step_name=custom code\n",
    "#step_type=import/export\n",
    "#step_desc= custom code\n",
    "# Your Custom Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=standardize_columns\n",
    "#step_name=standardize columns\n",
    "#step_type=data_cleaning\n",
    "#step_desc=remove spaces from data frame columns\n",
    "df.columns= df.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=lower_cols\n",
    "#step_name=lower columns\n",
    "#step_type=data_cleaning\n",
    "#step_desc=make the data frame columns a lower case.\n",
    "df.columns= df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=rename_cols\n",
    "#step_name=rename columns\n",
    "#step_type=data_cleaning\n",
    "#step_desc=renaming columns\n",
    "df = df.rename(columns=input_mapper)  \n",
    "# input_mapper -> {\"old_name\": \"new_name\", ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=drop_duplicates\n",
    "#step_name=drop duplicates\n",
    "#step_type=data_cleaning\n",
    "#step_desc=removing duplicates (entire row)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=drop_cols_high_perc_missing\n",
    "#step_name=drop high % of missing values\n",
    "#step_type=data_cleaning\n",
    "#step_desc=dropping column/ columns with high percentage of missing values\n",
    "def drop_columns_high_perc_missing(df, input_threshold=0.8):  # input_threshold -> float\n",
    "    column_list = []\n",
    "\n",
    "    for column in df.columns:\n",
    "\n",
    "        nan_ratio = df[column].isna().sum() / len(df[column])\n",
    "\n",
    "        if nan_ratio >= input_threshold:\n",
    "\n",
    "            column_list.append(column)\n",
    "\n",
    "    return df.drop(columns=column_list)\n",
    "\n",
    "# calling the function\n",
    "df = drop_columns_high_perc_missing(df, input_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=convert_cols_type\n",
    "#step_name=convert data type\n",
    "#step_type=data_cleaning\n",
    "#step_desc=correcting data type ( object to numeric, float to int, numeric to object)\n",
    "#input_mapper -> dict = {\"col\": \"data_type\", ...}\n",
    "df = df.astype(input_mapper) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=filter_rows_by_cond\n",
    "#step_name=filter pandas rows by condition\n",
    "#step_type=data_cleaning\n",
    "#step_desc=filter rows based on condition\n",
    "# column -> string / input_condition -> int, string, datetime, etc..\n",
    "df = df[df[column] == input_condition]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=filter_rows_by_index\n",
    "#step_name=filter pandas rows by index\n",
    "#step_type=data_cleaning\n",
    "#step_desc=filter rows by zero-based index  (iloc)\n",
    "# input_n0 -> int, left index of the slicing / input_nf -> int, right index of the slicing\n",
    "df = df.iloc[input_n0:input_nf, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=set_cols_values_by_cond\n",
    "#step_name=update pandas values\n",
    "#step_type=data_cleaning\n",
    "#step_desc=update pandas column specific values based on condition.\n",
    "# column -> string / input_condition -> int, string, datetime, etc. / input_value -> int, string, datetime, etc.\n",
    "df = df[df[column] == input_condition] = input_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=fill_missing_vals\n",
    "#step_name=filling missing values\n",
    "#step_type=data_cleaning\n",
    "#step_desc=filling missing values\n",
    "#  input_mapper -> dictionary mapping the strategy with the columns where it should be applied\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def fill_missing_vals(df, input_mapper):\n",
    "\n",
    "    for strategy, column_list in input_mapper.items():\n",
    "\n",
    "        imp_mean = SimpleImputer(missing_values=np.nan, strategy=strategy)  # the sklearn SimpleImputer is created\n",
    "        imp_mean.fit(df[column_list])  # the SimpleImputer is fitted using the target columns\n",
    "        df_target_columns_filled = imp_mean.transform(df[column_list])  # the target columns are transformed, i.e. nan values are filled\n",
    "    \n",
    "        df[column_list] = df_target_columns_filled  # the target columns of the main df are replaced by the filled ones\n",
    "\n",
    "    return df\n",
    "    \n",
    "## calling the function\n",
    "df = fill_missing_vals(df, input_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=remove_outliers\n",
    "#step_name=remove outliers\n",
    "#step_type=data_cleaning\n",
    "#step_desc=Removing outliers\n",
    "from scipy.stats import scoreatpercentile as pct\n",
    "from scipy.stats import iqr\n",
    "\n",
    "def remove_outliers(df):\n",
    "    pct_75 = pct(df, 75)  # Calculate percentile 75 using scipy function scoreatpercentile\n",
    "    pct_25 = pct(df, 25)  # Calculate percentile 25 using scipy function scoreatpercentile\n",
    "    upper_bound = pct_75 + 1.5*iqr(df)  # iqr - > Scipy function to calculate the Interquartile Range\n",
    "    lower_bound = pct_25 - 1.5*iqr(df)\n",
    "    df = df[(df <= upper_bound) & (df >= lower_bound)]  # Filter out the outliers\n",
    "    return df\n",
    "\n",
    "#calling the function\n",
    "df = remove_outliers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=drop_cols\n",
    "#step_name=drop columns\n",
    "#step_type=feature_selection\n",
    "#step_desc=drop one or more columns from the data frame.\n",
    "df = df.drop(columns=input_list)  # input_list -> [col1, col2, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=drop_high_corr_cols\n",
    "#step_name=drop highly corr cols\n",
    "#step_type=feature_selection\n",
    "#step_desc=dropping highly correlated columns\n",
    "# input_threshold -> float\n",
    "def drop_high_corr_cols(df, input_threshold=0.85):\n",
    "\n",
    "    highly_correlated_list = []  # the list that will contain the highly correlate features is initialized\n",
    "\n",
    "    numerical_features = df.select_dtypes(include='number')  # df including only the numerical features\n",
    "    correlation_matrix = numerical_features.corr()  # the correlation matrix is calculated\n",
    "\n",
    "    for row_index in range(len(correlation_matrix)):  # looping through the rows of the correlation matrix\n",
    "\n",
    "        for column_index in range(row_index+1, correlation_matrix.shape[1]): # looping through the columns of the matrix (only upper triangle)\n",
    "\n",
    "            correlation_coeff = correlation_matrix.iloc[row_index, column_index]  # the corresponding correlation coefficient\n",
    "\n",
    "            if correlation_coeff > input_threshold:  # checking that the coefficient is above the threshold (= highly correlated)\n",
    "\n",
    "                highly_correlated_list.append(correlation_matrix.columns[column_index])  # the column name is stored in the list\n",
    "\n",
    "    highly_correlated_list = list(set(highly_correlated_list))  # duplicated are removed from the list\n",
    "\n",
    "    return df.drop(columns=highly_corr_list)  # highly correlated features are dropped\n",
    "\n",
    "## calling the function\n",
    "df = drop_high_corr_cols(df, input_threshold=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=filter_by_P-value\n",
    "#step_name=filter by P-value\n",
    "#step_type=feature_selection\n",
    "#step_desc=filter by P-value\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def filter_by_pvalue(X_train=X_train, X_test=X_test, y_train=y_train):\n",
    "\n",
    "    p_value_list = []\n",
    "\n",
    "    X_train_const = sm.add_constant(X_train)  \n",
    "    model = sm.OLS(y_train, X_train_const).fit()  # OLS model is created\n",
    "    summary = model.summary().tables[1]  # SimpleTable with the p values is extracted\n",
    "    summary_df = pd.DataFrame(summary.data[1:])  # SimpleTable data is converted into DataFrame\n",
    "    summary_df.columns = summary.data[0]  # DataFrame formating\n",
    "    summary_df = (summary_df.set_index(summary_df[''])  # DataFrame formating\n",
    "                            .drop(columns=[''])\n",
    "                 )\n",
    "\n",
    "    for row_index in range(1,len(summary_df)):  # looping through the rows of summary_df (columns of the original data)\n",
    "\n",
    "        p_value = float(summary_df[\"P>|t|\"][row_index])  # p_value of the corresponding column is extracted\n",
    "\n",
    "        if p_value > 0.05:\n",
    "\n",
    "            p_value_list.append(summary_df.index[row_index])  # the features with a p_value above the are stored\n",
    "\n",
    "    # return X_train and X_test with the features dropped\n",
    "    return X_train.drop(columns=p_value_list), X_test.drop(columns=p_value_list)\n",
    "\n",
    "## calling the function\n",
    "X_train, X_test = filter_by_pvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=filter_by_RFE\n",
    "#step_name=recursive feature elemination\n",
    "#step_type=feature_selection\n",
    "#step_desc=recursive feature elemination\n",
    "# input_estimator -> sklearn model object, for example LinearRegression()\n",
    "# input_n_features_to_select -> integer\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "def filter_by_RFE(input_estimator, input_n_features_to_select, X_train=X_train, X_test=X_test, y_train=y_train):\n",
    "    \n",
    "    selector = RFE(input_estimator, n_features_to_select=input_n_features_to_select, step=1)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "    selected_features = selector.get_feature_names_out(X_train.columns)\n",
    "\n",
    "    return X_train[selected_features], X_test[selected_features]\n",
    "\n",
    "## calling the function\n",
    "X_train, X_test = filter_by_RFE(input_estimator, input_n_features_to_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=add_computed_cols\n",
    "#step_name=add computed features\n",
    "#step_type=feature_engineering\n",
    "#step_desc=adding computed features\n",
    "pd.DataFrame.drop(df,columns=[\"\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=bucket_cols\n",
    "#step_name=bucket/bin features\n",
    "#step_type=feature_engineering\n",
    "#step_desc= discretize the column into equal-sized bins and assigning them specific labels\n",
    "labels=[1,2,3]\n",
    "pd.cut(df[\"col-name\"], 3,labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=dummy_variables\n",
    "#step_name=create dummy variables\n",
    "#step_type=feature_transformation\n",
    "#step_desc=Convert categorical variable into dummy/indicator variables.\n",
    "pd.get_dummies(df, prefix=['col1', 'col2'], columns=[column1,column2],drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=apply_transformer\n",
    "#step_name=apply Transformer\n",
    "#step_type=feature_transformation\n",
    "#step_desc=applying transformer to transform the data. Options are StandardScaler, MinMaxScaler, PowerTransformer and QuantileTransformer\n",
    "def transform_data(data,method=\"StandardScaler\"):\n",
    "    if method == \"StandardScaler\":\n",
    "        transformer = preprocessing.StandardScaler()\n",
    "    elif method == \"MinMaxScaler\":\n",
    "        transformer = preprocessing.MinMaxScaler()\n",
    "    elif method == \"PowerTransformer\":\n",
    "        transformer = preprocessing.PowerTransformer()\n",
    "    elif method == \"QuantileTransformer\":\n",
    "        transformer= preprocessing.QuantileTransformer(random_state=0)\n",
    "    else: return \"No Trnasformation method is applied!\";\n",
    "\n",
    "    transformer = transformer.fit(data)\n",
    "    data=transformer.transform(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# transforming the data: data normally is X_train or X_test \n",
    "# or the whole numerical data as df._get_numeric_data()\n",
    "df=transform_data(df,method=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=sample_data\n",
    "#step_name=take random sample\n",
    "#step_type=data_sampling\n",
    "#step_desc=take random sample\n",
    "df.sample(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=XY_split\n",
    "#step_name=XY split\n",
    "#step_type=data_splitting\n",
    "#step_desc=XY split: splitting the tagret variable Y from the independent features.\n",
    "X=df.drop('target_col', axis=1)\n",
    "y=df[[\"target_col\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=numercials_cateogricals_split\n",
    "#step_name=numercials cateogricals split\n",
    "#step_type=data_splitting\n",
    "#step_desc=splitting the data into numerical and categorical features\n",
    "numericals_df=X._get_numeric_data()\n",
    "categoricals_df= X.select_dtypes(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=train_test_split\n",
    "#step_name=train test split\n",
    "#step_type=data_splitting\n",
    "#step_desc=splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test=model_selection.train_test_split(X, y, test_size=.20,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=linear_regression\n",
    "#step_name=Linear Regression\n",
    "#step_type=Regression\n",
    "#step_desc=Linear Regression\n",
    "model= lm.LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_train=model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=lasso_regression\n",
    "#step_name=Lasso Regression\n",
    "#step_type=Regression\n",
    "#step_desc=Lasso Regression\n",
    "model= lm.Lasso()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_train=model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=ridge_regression\n",
    "#step_name=ridge regression\n",
    "#step_type=Regression\n",
    "#step_desc=Ridge Regression\n",
    "model= lm.Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_train=model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=ElasticNet_regression\n",
    "#step_name=ElasticNet regression\n",
    "#step_type=Regression\n",
    "#step_desc=ElasticNet Regression\n",
    "model= lm.ElasticNet()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_train=model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=statsmodel_linear_regression\n",
    "#step_name=Statsmodel Linear Regression\n",
    "#step_type=Regression\n",
    "#step_desc=OLS using statsmodel\n",
    "X_train_const= sm.add_constant(X_train) # adding a constant\n",
    "\n",
    "model = sm.OLS(y_train, X_train_const).fit()\n",
    "predictions_train = model.predict(X_train_const) \n",
    "\n",
    "X_test_const = sm.add_constant(X_test) # adding a constant\n",
    "predictions_test = model.predict(X_test_const) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=Knn_regression\n",
    "#step_name=Knn regression\n",
    "#step_type=Regression\n",
    "#step_desc=Knn Regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor(n_neighbors=2)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_train=model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=Decision_Tree_Regression\n",
    "#step_name=Decision Tree Regression\n",
    "#step_type=Regression\n",
    "#step_desc=Decision Tree Regression\n",
    "model = DecisionTreeRegressor(max_depth=3,criterion='squared_error', \n",
    "                               max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "                               max_features=None, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred  = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=logisitc_regression\n",
    "#step_name=Logisitc Regression\n",
    "#step_type=Classification\n",
    "#step_desc=Logisitc Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(penalty='l2',random_state=0,multi_class='auto') \n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_train=model.predict(X_train)\n",
    "#model.predict_proba(inputdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=Knn_Classification\n",
    "#step_name=Knn Classification\n",
    "#step_type=Classification\n",
    "#step_desc=Knn Classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=2,weights='uniform')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_train=model.predict(X_train)\n",
    "#model.predict_proba(inputdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=Decision_Tree_Classification\n",
    "#step_name=Decision Tree Classification\n",
    "#step_type=Regression\n",
    "#step_desc=Decision Tree Classification\n",
    "from sklearn import tree\n",
    "model=tree.DecisionTreeClassifier(criterion='gini', max_depth=None, \n",
    "                            min_samples_split=2, min_samples_leaf=1, \n",
    "                            max_features=None, random_state=None)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_train=model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=kmeans_clustering\n",
    "#step_name=K-means\n",
    "#step_type=Clustering\n",
    "#step_desc=K-means\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=5,\n",
    "                init=\"k-means++\",\n",
    "                n_init=50,  # try with 1, 4, 8, 20, 30, 100...\n",
    "                max_iter=10,\n",
    "                tol=0,\n",
    "                algorithm=\"elkan\",\n",
    "                random_state=1234)\n",
    "\n",
    "model.fit(df)\n",
    "clusters = model.predict(df)\n",
    "#get the distribution of the clusters\n",
    "print(pd.Series(clusters).value_counts().sort_index())\n",
    "\n",
    "## model error\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=regression_model_parameters\n",
    "#step_name=Regression Model Parameters\n",
    "#step_type=model_validation\n",
    "#step_desc=Regression Model Parameters; coeffecients and intercept\n",
    "pd.Series([model.intercept_]+ list(model.coef_),index=[\"Intercept\"]+list(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=regression_model_evaluating\n",
    "#step_name=Regression Model Metrics\n",
    "#step_type=model_validation\n",
    "#step_desc=Regression Model Metrics\n",
    "def evaluate_regression_model(y_train, y_pred_train, y_test, y_pred_test):\n",
    "\n",
    "    ME_train = np.mean(y_train - y_pred_train)\n",
    "    ME_test  = np.mean(y_test - y_pred_test)\n",
    "\n",
    "    MAE_train = metrics.mean_absolute_error(y_train,y_pred_train)\n",
    "    MAE_test  = metrics.mean_absolute_error(y_test,y_pred_test)\n",
    "\n",
    "    MSE_train = metrics.mean_squared_error(y_train,y_pred_train)\n",
    "    MSE_test  = metrics.mean_squared_error(y_test,y_pred_test)\n",
    "\n",
    "    RMSE_train = np.sqrt(MSE_train)\n",
    "    RMSE_test  = np.sqrt(MSE_test)\n",
    "\n",
    "    MAPE_train = np.mean((np.abs(y_train- y_pred_train) / y_train)* 100.)\n",
    "    MAPE_test  = np.mean((np.abs(y_test-y_pred_test) / np.exp(y_test))* 100.)\n",
    "\n",
    "    R2_train = metrics.r2_score(y_train,y_pred_train)\n",
    "    R2_test  = metrics.r2_score(y_test,y_pred_test)\n",
    "\n",
    "    adjusted_R2_train = 1 - (1-R2_train)*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
    "    adjusted_R2_test = 1 - (1-R2_test)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "    \n",
    "    performance = pd.DataFrame({'Error_metric': ['Mean error','Mean absolute error','Mean squared error',\n",
    "                                             'Root mean squared error','Mean absolute percentual error',\n",
    "                                             'R2','adjusted_R2'],\n",
    "                            'Train': [ME_train, MAE_train, MSE_train, RMSE_train, MAPE_train, R2_train,adjusted_R2_train],\n",
    "                            'Test' : [ME_test, MAE_test , MSE_test, RMSE_test, MAPE_test, R2_test,adjusted_R2_test]})\n",
    "\n",
    "    pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "    df_train = pd.DataFrame({'Real': y_train, 'Predicted': y_pred_train})\n",
    "    df_test  = pd.DataFrame({'Real': y_test,  'Predicted': y_pred_test})\n",
    "\n",
    "    return performance, df_train, df_test\n",
    "\n",
    "## calling the function \n",
    "error_metrics_df,y_train_vs_predicted, y_test_vs_predicted=evaluate_regression_model(y_train, model.predict(X_train),y_test,y_pred)\n",
    "error_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=regression_multi_models_evaluating\n",
    "#step_name=Regression Multiple Models Metrics\n",
    "#step_type=model_validation\n",
    "#step_desc=Regression Model Metrics\n",
    "\n",
    "def evaluate_regression_model(y_train, y_pred_train, y_test, y_pred_test):\n",
    "\n",
    "    ME_train = np.mean(y_train - y_pred_train)\n",
    "    ME_test  = np.mean(y_test - y_pred_test)\n",
    "\n",
    "    MAE_train = metrics.mean_absolute_error(y_train,y_pred_train)\n",
    "    MAE_test  = metrics.mean_absolute_error(y_test,y_pred_test)\n",
    "\n",
    "    MSE_train = metrics.mean_squared_error(y_train,y_pred_train)\n",
    "    MSE_test  = metrics.mean_squared_error(y_test,y_pred_test)\n",
    "\n",
    "    RMSE_train = np.sqrt(MSE_train)\n",
    "    RMSE_test  = np.sqrt(MSE_test)\n",
    "\n",
    "    MAPE_train = np.mean((np.abs(y_train- y_pred_train) / y_train)* 100.)\n",
    "    MAPE_test  = np.mean((np.abs(y_test-y_pred_test) / np.exp(y_test))* 100.)\n",
    "\n",
    "    R2_train = metrics.r2_score(y_train,y_pred_train)\n",
    "    R2_test  = metrics.r2_score(y_test,y_pred_test)\n",
    "\n",
    "    adjusted_R2_train = 1 - (1-R2_train)*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
    "    adjusted_R2_test = 1 - (1-R2_test)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "    \n",
    "    performance = pd.DataFrame({'Error_metric': ['Mean error','Mean absolute error','Mean squared error',\n",
    "                                             'Root mean squared error','Mean absolute percentual error',\n",
    "                                             'R2','adjusted_R2'],\n",
    "                            'Train': [ME_train, MAE_train, MSE_train, RMSE_train, MAPE_train, R2_train,adjusted_R2_train],\n",
    "                            'Test' : [ME_test, MAE_test , MSE_test, RMSE_test, MAPE_test, R2_test,adjusted_R2_test]})\n",
    "\n",
    "    pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "    df_train = pd.DataFrame({'Real': y_train, 'Predicted': y_pred_train})\n",
    "    df_test  = pd.DataFrame({'Real': y_test,  'Predicted': y_pred_test})\n",
    "\n",
    "    return performance, df_train, df_test\n",
    "\n",
    "def evaluate_multiple_regression_models(X_train,y_train,X_test,y_test):\n",
    "    models={\"LinearRegression\":lm.LinearRegression(),\"Lasso\":lm.Lasso(),\"Ridge\":lm.Ridge(),\"ElasticNet\":lm.ElasticNet()}\n",
    "    performances=[]\n",
    "\n",
    "    for key in models.keys():\n",
    "        models[key].fit(X_train, y_train)\n",
    "        y_pred=models[key].predict(X_test)\n",
    "        y_pred_train=models[key].predict(X_train)\n",
    "\n",
    "        perforamnce,y_train_vs_predicted, y_test_vs_predicted=evaluate_regression_model(y_train, y_pred_train,y_test,y_pred)\n",
    "        perforamnce.columns=[\"Error_metric\",key+\"_Train\", key+\"_Test\"]\n",
    "        performances.append(perforamnce)\n",
    "\n",
    "    reg_models_err_metrics_df=pd.concat(performances,axis=1)\n",
    "    del performances; \n",
    "    reg_models_err_metrics_df = reg_models_err_metrics_df.loc[:,~reg_models_err_metrics_df.columns.duplicated()]\n",
    "    return reg_models_err_metrics_df\n",
    "\n",
    "evaluate_multiple_regression_models(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=classification_model_evaluating\n",
    "#step_name=Classification Model Metrics\n",
    "#step_type=model_validation\n",
    "#step_desc=Classification Model Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "def evaluate_classification_model(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    performance_df = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train),\n",
    "                                         precision_score(y_train, y_pred_train),\n",
    "                                         recall_score(y_train, y_pred_train)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test),\n",
    "                                        precision_score(y_test, y_pred_test),\n",
    "                                        recall_score(y_test, y_pred_test)]})\n",
    "    \n",
    "    pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "    df_train = pd.DataFrame({'Real': y_train, 'Predicted': y_pred_train})\n",
    "    df_test  = pd.DataFrame({'Real': y_test,  'Predicted': y_pred_test})\n",
    "\n",
    "    return performance_df, df_train, df_test\n",
    "\n",
    "## calling the function\n",
    "error_metrics_df,y_train_vs_predicted, \\\n",
    "    y_test_vs_predicted=evaluate_classification_model(y_train, y_pred_train,\n",
    "                                                    y_test, y_pred)\n",
    "error_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=classification_plot_confusion_matrix\n",
    "#step_name=Classification Plot Confusion Matrix\n",
    "#step_type=model_validation\n",
    "#step_desc=Classification Model confusion matrix for training and test set\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(14,8))\n",
    "\n",
    "plot_confusion_matrix(model,X_train,y_train,ax=ax[0], values_format = 'd')\n",
    "ax[0].title.set_text(\"Train Set\")\n",
    "\n",
    "plot_confusion_matrix(model,X_test,y_test,ax=ax[1],values_format = 'd')\n",
    "ax[1].title.set_text(\"Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=plot_decision_tree\n",
    "#step_name=plot decision tree\n",
    "#step_type=model_validation\n",
    "#step_desc=plot decision tree\n",
    "from sklearn.tree import plot_tree\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (20,10))\n",
    "plot_tree(dt,filled = True, rounded=True,feature_names=X.columns)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=Clustering_Elbow_Method\n",
    "#step_name=Clustering Elbow Method\n",
    "#step_type=model_validation\n",
    "#step_desc=Clustering Elbow Method\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "K = range(2, 21)\n",
    "inertia = []\n",
    "\n",
    "for k in K:\n",
    "    print(\"Training a K-Means model with {} clusters! \".format(k))\n",
    "    print()\n",
    "    model = KMeans(n_clusters=k,\n",
    "                    random_state=1234)\n",
    "    model.fit(X_scaled_df)\n",
    "    inertia.append(model.inertia_)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, inertia, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(np.arange(min(K), max(K)+1, 1.0))\n",
    "plt.title('Elbow Method showing the optimal k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_id=Clustering_Silhouette_Method\n",
    "#step_name=Clustering Silhouette Method\n",
    "#step_type=model_validation\n",
    "#step_desc=Clustering Silhouette Method\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "K = range(2, 20)\n",
    "silhouette = []\n",
    "\n",
    "for k in K:\n",
    "    model = KMeans(n_clusters=k,\n",
    "                    random_state=1234)\n",
    "    model.fit(X_scaled_df)\n",
    "    \n",
    "    silhouette.append(silhouette_score(scaled_df, kmeans.predict(scaled_df)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, silhouette, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('silhouette score')\n",
    "plt.xticks(np.arange(min(K), max(K)+1, 1.0))\n",
    "plt.title('Silhouette Method showing the optimal k')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
